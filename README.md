---

# üöÄ IA-WebChat ‚Äì Configura√ß√£o no Google Colab  

Este projeto configura um ambiente no **Google Colab** para rodar **modelos de IA via Ollama**, utilizando o **Xterm** para um terminal interativo. A conversa com a IA acontece em uma **p√°gina web** acessada remotamente atrav√©s da conex√£o criada com **Ngrok**.  

## ‚öôÔ∏è Instala√ß√£o  

### 1Ô∏è‚É£ **Configurar o Xterm**  
Instale o terminal interativo para executar comandos no Colab:  

```python
!pip install colab-xterm  
%load_ext colabxterm  
%xterm  
```

### 2Ô∏è‚É£ **Instalar e executar o Ollama**  
Baixe e instale o **Ollama**, deixando-o rodando em segundo plano:  

```bash
curl https://ollama.ai/install.sh | sh  
ollama serve &  
```

### 3Ô∏è‚É£ **Baixar e executar um modelo LLM**  
Escolha um modelo dispon√≠vel no **Ollama** e execute-o. Exemplo:  

```bash
ollama run llama3.2:1b  
```

## üåê Conectar a IA via p√°gina web (Ngrok)  
Para acessar a IA remotamente, use **Ngrok** para expor o servidor Flask na web:  

```bash
!pip install pyngrok  
ngrok config add-authtoken <SEU_TOKEN_AQUI>  
```

Depois que o **Ngrok** iniciar, ele fornecer√° um **link p√∫blico**, que ser√° a **p√°gina web** onde voc√™ poder√° conversar com a IA.  

## üõ†Ô∏è Testar a conex√£o com IA  
Envie mensagens para o chatbot via **requisi√ß√£o POST**:  

```bash
curl -X POST -H "Content-Type: application/json" -d '{"message": "Ol√°"}' https://SEU_NGROK_URL/chat  
```

---
